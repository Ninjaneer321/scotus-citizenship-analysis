{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re;\n",
    "import pandas as pd;\n",
    "import geopandas as gpd;\n",
    "import numpy as np;\n",
    "import requests\n",
    "from census import Census\n",
    "from us import states\n",
    "\n",
    "raw_dir='raw_data/'\n",
    "edits_dir='edits/'\n",
    "pre_edits_dir='pre_edits_hard_to_count/'\n",
    "output_dir='output/'\n",
    "\n",
    "chambers = ['congress', 'state_house', 'state_senate']\n",
    "\n",
    "# To reproduce the data below, you'll need to save your \n",
    "# Census API key to `../data/census-api-key.txt`.\n",
    "# You can obtain a key here: https://api.census.gov/data/key_signup.html\n",
    "api_key = open(\"census-api-key.txt\").read().strip()\n",
    "c = Census(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done creating cached version of Census API data\n"
     ]
    }
   ],
   "source": [
    "# We don't want to have to call the API every time\n",
    "# So we'll create a cached version in memory\n",
    "# Which we'll have to re-run every time we close out the window\n",
    "acs_data_cache = []\n",
    "\n",
    "# Our Census API call\n",
    "def get_acs_data(chamber):\n",
    "    if chamber == 'congress':\n",
    "        api_geo = 'congressional district'\n",
    "        leg_year = '115th Congress'\n",
    "    elif chamber == 'state_senate':\n",
    "        api_geo = 'state legislative district (upper chamber)'\n",
    "        leg_year = '2016'\n",
    "    elif chamber == 'state_house':\n",
    "        api_geo = 'state legislative district (lower chamber)'\n",
    "        leg_year = '2016'\n",
    "    \n",
    "    results = c.acs5.get(\n",
    "        [\n",
    "            # Total population\n",
    "            'B05002_001E', 'B05002_001M',\n",
    "            # Native\n",
    "            'B05002_002E', 'B05002_002M',\n",
    "            # Foreign born\n",
    "            'B05002_013E', 'B05002_013M',\n",
    "            # Not a citizen\n",
    "            'B05002_021E', 'B05002_021M',\n",
    "        ],\n",
    "        geo={'for': '{}:*'.format(api_geo),\n",
    "             'in': 'state:{}'.format(states.TX.fips)\n",
    "        })\n",
    "        \n",
    "    return [ {\n",
    "        'district': int(res[api_geo]),\n",
    "        'leg_year': leg_year,\n",
    "        'pop': res['B05002_001E'],\n",
    "        'pop_moe': res['B05002_001M'],\n",
    "        'native': res['B05002_002E'],\n",
    "        'native_moe': res['B05002_002M'],\n",
    "        'foreign_born': res['B05002_013E'],\n",
    "        'foreign_born_moe': res['B05002_013M'],\n",
    "        'not_citizen': res['B05002_021E'],\n",
    "        'not_citizen_moe': res['B05002_021M'],\n",
    "        'not_citizen_perc': round((res['B05002_021E'] / res['B05002_001E']) * 100, 1),\n",
    "        'not_citizen_moe_perc': round((res['B05002_021M'] / res['B05002_001E']) * 100, 1)\n",
    "    } for res in results ]\n",
    "\n",
    "\n",
    "for chamber in chambers:\n",
    "    acs_data_cache.append({\n",
    "        'chamber': chamber,\n",
    "        'data': get_acs_data(chamber)\n",
    "    })\n",
    "\n",
    "def get_acs_data_cache(chamber):\n",
    "    for x in acs_data_cache:\n",
    "        if x['chamber'] == chamber:\n",
    "            return x['data']\n",
    "        \n",
    "print('Done creating cached version of Census API data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on the congress sheet\n",
      "Calling Census API\n",
      "Done with Census API\n",
      "Done with districts csv\n",
      "Done with summary csv\n",
      "---\n",
      "Working on the state_house sheet\n",
      "Calling Census API\n",
      "Done with Census API\n",
      "Done with districts csv\n",
      "Done with summary csv\n",
      "---\n",
      "Working on the state_senate sheet\n",
      "Calling Census API\n",
      "Done with Census API\n",
      "Done with districts csv\n",
      "Done with summary csv\n",
      "---\n",
      "Done with everything\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Analysis for each chamber\n",
    "for chamber in chambers:\n",
    "    print('Working on the ' + chamber + ' sheet')\n",
    "    \n",
    "    # Download data using Census API\n",
    "    # End up with foreign born info for each chamber\n",
    "    print('Calling Census API')\n",
    "    census_api_data = get_acs_data_cache(chamber)\n",
    "    census_cols = list(census_api_data[0].keys())\n",
    "    df_main = pd.DataFrame(census_api_data, columns=census_cols)\n",
    "    \n",
    "    print('Done with Census API')\n",
    "    \n",
    "    # Use these files to merge party\n",
    "    # Congressional districts are pulled from our voter tracker\n",
    "    if chamber == 'congress':\n",
    "        df_party = pd.read_csv(raw_dir + 'delegation_tracker_2019_congress.csv')\n",
    "        df_party = df_party[df_party['district'].apply(str) != 'FALSE']\n",
    "        df_party['district'] = df_party['district'].apply(int)\n",
    "        df_party['party'] = df_party['party'].str.replace('Democrat ', 'D').replace('Republican', 'R')\n",
    "    # State legislative districts are pulled from demographics sheet we track\n",
    "    else:\n",
    "        df_party = pd.read_csv(raw_dir + 'demographics_tx_lege_2019_' + chamber + '.csv')\n",
    "        df_party.columns = map(str.lower, df_party.columns)\n",
    "        \n",
    "    # Merge the current dataframe with csv that has party info\n",
    "    df_main = df_main.merge(df_party, on='district')\n",
    "    \n",
    "    # Select columns\n",
    "    df_main_select = df_main[[\n",
    "        'district', 'leg_year',\n",
    "        'pop', 'native', 'foreign_born',\n",
    "        'not_citizen', 'not_citizen_perc', 'party'\n",
    "    ]].sort_values(by='not_citizen_perc', ascending=False)\n",
    "\n",
    "    df_main_select_moe = df_main[[\n",
    "        'district', 'leg_year',\n",
    "        'pop_moe', 'native_moe', 'foreign_born_moe',\n",
    "        'not_citizen_moe', 'not_citizen_moe_perc'\n",
    "    ]].sort_values(by='not_citizen_moe_perc', ascending=False)\n",
    "\n",
    "    # Output percent cols\n",
    "    df_main_select.to_csv(output_dir + 'tx_' + chamber + '_not_citizen.csv', index=False)\n",
    "    df_main_select_moe.to_csv(output_dir + 'tx_' + chamber + '_not_citizen_moe.csv', index=False)\n",
    "    print('Done with districts csv')\n",
    "\n",
    "    # Summary stats for population in districts\n",
    "    pop_groupby = df_main.groupby(['leg_year'])['pop']\n",
    "    sum_all_districts = pop_groupby.agg('sum').values[0]\n",
    "    median_all_districts = pop_groupby.agg('median').values[0]\n",
    "\n",
    "    # Summary stats for foreign population in districts\n",
    "    not_citizen_groupby = df_main.groupby(['leg_year'])['not_citizen']\n",
    "    count_not_citizen = not_citizen_groupby.agg('count').values[0]\n",
    "    sum_not_citizen = not_citizen_groupby.agg('sum').values[0]\n",
    "    median_not_citizen = round(not_citizen_groupby.agg('median'), 1).values[0]\n",
    "    mean_not_citizen = round(not_citizen_groupby.agg('mean'), 1).values[0]\n",
    "\n",
    "    # Create our final csv with these stats\n",
    "    df_summary = pd.DataFrame(columns=['calculation', 'value'])\n",
    "    c_loc = 0\n",
    "    df_summary.loc[c_loc] = ['count_districts', count_not_citizen]\n",
    "    c_loc += 1\n",
    "    df_summary.loc[c_loc] = ['pop_not_citizen', sum_not_citizen]\n",
    "    c_loc += 1\n",
    "    df_summary.loc[c_loc] = ['pop_all', sum_all_districts]\n",
    "    c_loc += 1\n",
    "    df_summary.loc[c_loc] = ['not_citizen_pop_all_perc', round((sum_not_citizen / sum_all_districts) * 100, 1)]\n",
    "    c_loc += 1\n",
    "    df_summary.loc[c_loc] = ['median_pop_all_districts', median_all_districts]\n",
    "    c_loc += 1\n",
    "    df_summary.loc[c_loc] = ['not_citizen_pop_in_median_district', round(sum_not_citizen / median_all_districts, 1)]\n",
    "    \n",
    "    parties = ['D', 'R']\n",
    "    for party in parties:\n",
    "        c_df_main_party = df_main[df_main['party'] == party]\n",
    "        not_citizen_party_groupby = c_df_main_party.groupby(['party'])['not_citizen']\n",
    "        sum_not_citizen_party = not_citizen_party_groupby.agg('sum').values[0]\n",
    "\n",
    "        c_loc += 1\n",
    "        df_summary.loc[c_loc] = ['pop_not_citizen_' + party + '_districts', sum_not_citizen_party]\n",
    "        c_loc += 1\n",
    "        df_summary.loc[c_loc] = ['not_citizen_pop_in_' + party + '_districts_perc', round((sum_not_citizen_party / sum_not_citizen) * 100, 1)]\n",
    "    \n",
    "    # Save our file\n",
    "    df_summary.to_csv(output_dir + 'tx_' + chamber + '_not_citizen_summary.csv', index=False)\n",
    "    print('Done with summary csv')\n",
    "    print('---')\n",
    "\n",
    "print('Done with everything')\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
